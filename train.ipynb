{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542098e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "# Rice Type Detection Training Notebook\n",
    "\n",
    "#This notebook demonstrates how to train a deep learning model to classify rice grain types using the Rice Image Dataset from Kaggle. We will use transfer learning with MobileNetV2, data augmentation, and evaluate the model's performance.\n",
    "\n",
    "'''---\n",
    "\n",
    "**Steps covered in this notebook:**\n",
    "1. Import required libraries\n",
    "2. Load and explore the dataset\n",
    "3. Data preprocessing and augmentation\n",
    "4. Build and train the model (using MobileNetV2)\n",
    "5. Evaluate and save the model'''\n",
    "pip install numpy\n",
    "pip install pandas\n",
    "pip install tensorflow==2.3.2\n",
    "pip install keras==2.3.1\n",
    "pip install Flask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da918107",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.11' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "# Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import pathlib\n",
    "import cv2  # Added for image reading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d6f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the data directory and list sample files for each rice type\n",
    "\n",
    "data_dir = \"../input/rice-image-dataset/Rice_Image_Dataset\"  # Update path as needed\n",
    "\n",
    "data_dir = pathlib.Path(data_dir)\n",
    "\n",
    "# List a few sample images from each class (limit to 600 for demonstration)\n",
    "arborio = list(data_dir.glob('Arborio/*'))[:600]\n",
    "basmati = list(data_dir.glob('Basmati/*'))[:600]\n",
    "ipsala = list(data_dir.glob('Ipsala/*'))[:600]\n",
    "jasmine = list(data_dir.glob('Jasmine/*'))[:600]\n",
    "karacadag = list(data_dir.glob('Karacadag/*'))[:600]\n",
    "\n",
    "# Display counts for each class\n",
    "print('Arborio:', len(arborio))\n",
    "print('Basmati:', len(basmati))\n",
    "print('Ipsala:', len(ipsala))\n",
    "print('Jasmine:', len(jasmine))\n",
    "print('Karacadag:', len(karacadag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69d99db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains the images path\n",
    "df_images = {\n",
    "    'arborio': arborio,\n",
    "    'basmati': basmati,\n",
    "    'ipsala': ipsala,\n",
    "    'jasmine': jasmine,\n",
    "    'karacadag': karacadag\n",
    "}\n",
    "\n",
    "# Contains numerical labels for the categories\n",
    "df_labels = {\n",
    "    'arborio': 0,\n",
    "    'basmati': 1,\n",
    "    'ipsala': 2,\n",
    "    'jasmine': 3,\n",
    "    'karacadag': 4\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bc5361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and labels into X and y lists\n",
    "X = []\n",
    "y = []\n",
    "img_size = 250  # Assuming images are 250x250 as shown in the screenshot\n",
    "\n",
    "for label_name, images in df_images.items():\n",
    "    for img_path in images:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        img = cv2.resize(img, (img_size, img_size))\n",
    "        X.append(img)\n",
    "        y.append(df_labels[label_name])\n",
    "\n",
    "print(f\"Loaded {len(X)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01493b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing\n",
    "X = np.array(X)\n",
    "X = X / 255\n",
    "y = np.array(y)\n",
    "\n",
    "# Separating data into training, test and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test_val, y_train, y_test_val = train_test_split(X, y)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test_val, y_test_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba15e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one sample image from each rice category\n",
    "fig, ax = plt.subplots(ncols=5, figsize=(20, 5))\n",
    "fig.suptitle('Rice Category')\n",
    "\n",
    "arborio_image = cv2.imread(str(arborio[0]))\n",
    "basmati_image = cv2.imread(str(basmati[0]))\n",
    "ipsala_image = cv2.imread(str(ipsala[0]))\n",
    "jasmine_image = cv2.imread(str(jasmine[0]))\n",
    "karacadag_image = cv2.imread(str(karacadag[0]))\n",
    "\n",
    "ax[0].set_title('arborio')\n",
    "ax[1].set_title('basmati')\n",
    "ax[2].set_title('ipsala')\n",
    "ax[3].set_title('jasmine')\n",
    "ax[4].set_title('karacadag')\n",
    "\n",
    "ax[0].imshow(cv2.cvtColor(arborio_image, cv2.COLOR_BGR2RGB))\n",
    "ax[1].imshow(cv2.cvtColor(basmati_image, cv2.COLOR_BGR2RGB))\n",
    "ax[2].imshow(cv2.cvtColor(ipsala_image, cv2.COLOR_BGR2RGB))\n",
    "ax[3].imshow(cv2.cvtColor(jasmine_image, cv2.COLOR_BGR2RGB))\n",
    "ax[4].imshow(cv2.cvtColor(karacadag_image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50c56fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MobileNetV2 as a feature extractor (freeze convolutional layers) using keras.Sequential\n",
    "input_shape = (224, 224, 3)\n",
    "num_label = 5  # number of labels\n",
    "\n",
    "# Resize images if needed\n",
    "X_train_resized = np.array([cv2.resize(img, (224, 224)) for img in X_train])\n",
    "X_val_resized = np.array([cv2.resize(img, (224, 224)) for img in X_val])\n",
    "X_test_resized = np.array([cv2.resize(img, (224, 224)) for img in X_test])\n",
    "\n",
    "# Load MobileNetV2 with pretrained ImageNet weights, exclude top layers\n",
    "mobile_net = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape, pooling='avg')\n",
    "mobile_net.trainable = False  # Freeze all convolutional layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    mobile_net,\n",
    "    keras.layers.Dense(num_label)\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=['acc']\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_resized, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_val_resized, y_val)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3b0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = model.predict(X_test_resized, batch_size=64, verbose=1)\n",
    "y_pred_bool = np.argmax(y_pred, axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred_bool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8321af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "acc = pd.DataFrame({'train': history.history['acc'], 'val': history.history['val_acc']})\n",
    "\n",
    "fig = px.line(acc, x=acc.index, y=acc.columns[0:],'title=\"Training and Evaluation Accuracy every Epoch\" , markers=True)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db1f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on a single image\n",
    "\n",
    "a1 = cv2.imread(\"../input/rice-image-dataset/Rice_Image_Dataset/Basmati/basmati (10).jpg\")\n",
    "a1 = cv2.resize(a1, (224,224))\n",
    "a1 = np.array(a1)\n",
    "a1 = a1/255\n",
    "a1 = np.expand_dims(a1, 0)\n",
    "pred = model.predict(a1)\n",
    "pred = pred.argmax()\n",
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce216987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save(\"rice.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
